# Desafio 2: Biblioteca de Pr√©-Processamento de Dados

## üìù Vis√£o Geral do Desafio

> Sejam bem-vindos √† segunda etapa do nosso programa! Como vimos no desafio anterior, o principal objetivo de qualquer plataforma √© auxiliar os consumidores na atividade mais complexa que todos eles possuem: escolher o que consumir. O nosso objetivo ao longo deste semestre √© desenvolver o nosso modelo de recomenda√ß√£o para os usu√°rios. Como trainees da √°rea de dados, voc√™s est√£o no segundo desafio. Estamos numa etapa de pr√©-processamento dos nossos dados. Voc√™s v√£o perceber que quanto melhor o tratamento dos dados, mais preciso e eficiente ser√° o nosso modelo.

Este reposit√≥rio cont√©m a solu√ß√£o para o desafio, que consiste na cria√ß√£o de uma biblioteca Python robusta para realizar as tarefas mais comuns de pr√©-processamento de dados, preparando um dataset para as futuras etapas de modelagem de machine learning.

## üìñ Tabela de Conte√∫dos

- [A Import√¢ncia do Pr√©-Processamento](#-a-import√¢ncia-do-pr√©-processamento)
- [Funcionalidades Implementadas](#-funcionalidades-implementadas)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Como Utilizar a Biblioteca](#-como-utilizar-a-biblioteca)
- [Como Executar os Testes](#-como-executar-os-testes)

## üéØ A Import√¢ncia do Pr√©-Processamento

Antes de construirmos qualquer modelo de aprendizado de m√°quina, precisamos garantir que os dados que o alimentar√£o sejam de alta qualidade. O pr√©-processamento √© a etapa mais crucial e, muitas vezes, a que consome mais tempo em um projeto de dados. √â aqui que transformamos dados brutos e "sujos" em um formato limpo, consistente e compreens√≠vel para os algoritmos.

Um tratamento cuidadoso e met√≥dico assegura a integridade e a confiabilidade dos dados, permitindo que os algoritmos aprendam padr√µes verdadeiros de comportamento do consumidor, o que resulta em sugest√µes mais personalizadas e assertivas para nosso modelo de recomenda√ß√£o.

## ‚ú® Funcionalidades Implementadas

A biblioteca `preprocessing` foi constru√≠da de forma modular e encapsulada na classe principal `Preprocessing`. Ela oferece uma API simples e fluente (com encadeamento de m√©todos) para tratar os seguintes desafios:

### 1. Tratamento de Dados Ausentes (`MissingValueProcessor`)
A presen√ßa de dados ausentes ou nulos (`None`/`NaN`) √© um desafio comum. A biblioteca oferece estrat√©gias flex√≠veis para lidar com eles:
- **`isna()`**: Identifica e retorna todas as linhas que cont√™m valores nulos em colunas espec√≠ficas.
- **`notna()`**: O inverso de `isna`, retorna todas as linhas que **n√£o** cont√™m valores nulos.
- **`fillna()`**: Preenche valores ausentes utilizando m√©todos estat√≠sticos (`mean`, `median`, `mode`) ou um valor padr√£o.
- **`dropna()`**: Remove completamente as linhas que cont√™m dados faltantes.

### 2. Escalonamento de Dados Num√©ricos (`Scaler`)
Algoritmos de machine learning podem ser sens√≠veis a features com escalas muito diferentes. Para evitar vieses, implementamos dois m√©todos de escalonamento:
- **`minMax_scaler()`**: Normaliza os dados para um intervalo fixo (geralmente [0, 1]).
- **`standard_scaler()`**: Padroniza os dados, resultando em uma distribui√ß√£o com m√©dia 0 e desvio padr√£o 1 (Z-score).

### 3. Codifica√ß√£o de Dados Categ√≥ricos (`Encoder`)
Modelos de machine learning operam com n√∫meros, n√£o com texto. Nossos encoders traduzem vari√°veis categ√≥ricas para um formato num√©rico:
- **`label_encode()`**: Atribui um n√∫mero inteiro √∫nico para cada categoria em uma coluna.
- **`oneHot_encode()`**: Cria novas colunas bin√°rias (0 ou 1) para cada categoria, evitando a cria√ß√£o de uma rela√ß√£o de ordem artificial.

## üìÇ Estrutura do Projeto

O reposit√≥rio est√° organizado da seguinte forma:

```
.
‚îú‚îÄ‚îÄ preprocessing.py    # O m√≥dulo principal contendo todas as classes da biblioteca.
‚îú‚îÄ‚îÄ test_preprocessing.py   # O arquivo com os testes unit√°rios para a biblioteca.
‚îú‚îÄ‚îÄ food_statistics.py   # O arquivo contendo a classe de Statistics implementada no primeiro desafio
‚îî‚îÄ‚îÄ README.md               # Este arquivo.
```

## üöÄ Como Utilizar a Biblioteca

A classe principal `Preprocessing` serve como uma fachada, simplificando o uso de todas as funcionalidades. Abaixo est√° um exemplo pr√°tico de uso:

```python
# Importe a classe principal
from preprocessing_lib import Preprocessing

# 1. Carregue seu dataset no formato de dicion√°rio
dados = {
    'idade': [25, 30, None, 45],
    'salario': [50000, 60000, 45000, None],
    'cidade': ['Recife', 'Salvador', 'Recife', 'S√£o Paulo']
}

# 2. Instancie a classe de pr√©-processamento
preprocessador = Preprocessing(dados)

# 3. Aplique as transforma√ß√µes de forma encadeada
preprocessador.fillna(columns={'idade'}, method='mean') \
              .fillna(columns={'salario'}, method='median') \
              .scale(columns={'idade', 'salario'}, method='standard') \
              .encode(columns={'cidade'}, method='oneHot')

# 4. O dataset original foi modificado e est√° pronto para uso
print(preprocessador.dataset)
```

## ‚úÖ Como Executar os Testes

Para garantir a confiabilidade e o correto funcionamento da biblioteca, foi criada uma su√≠te de testes unit√°rios utilizando o m√≥dulo `unittest` do Python.

Para executar os testes, abra seu terminal na raiz do projeto e execute o seguinte comando:

```bash
python -m unittest test_preprocessing.py
```

A sa√≠da esperada √© uma mensagem indicando que todos os testes passaram (`OK`). Isso confirma que todas as funcionalidades da biblioteca est√£o operando conforme o esperado.
